{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-05T01:15:35.518880Z",
     "start_time": "2024-05-05T01:15:35.510740Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import xgboost\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import duckdb"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T01:15:35.651895Z",
     "start_time": "2024-05-05T01:15:35.647167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from binding_prediction.const import WHOLE_MOLECULE_COLUMN, TARGET_COLUMN\n",
    "\n",
    "from binding_prediction.datasets.xgboost_iterator import SmilesIterator\n",
    "\n",
    "from binding_prediction.evaluation.kaggle_submission_creation import get_submission_test_predictions_for_xgboost_model\n"
   ],
   "id": "25603d18051c6198",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EDA",
   "id": "e77e751c211e9695"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Get train dataset info",
   "id": "4a433470bdfa6ec7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T01:15:35.670294Z",
     "start_time": "2024-05-05T01:15:35.667989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_path = 'data/train.parquet'\n",
    "test_path = 'data/test.parquet'"
   ],
   "id": "8d732965d39dfc64",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-05T01:15:35.702345Z"
    }
   },
   "cell_type": "code",
   "source": "parquet_file = pq.ParquetFile('data/train.parquet')",
   "id": "6a2fd5cbbfca8f8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "parquet_file.metadata",
   "id": "13da34df6df04aed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row_group_0 = parquet_file.read_row_group(0)\n",
    "row_group_1 = parquet_file.read_row_group(1)\n",
    "\n",
    "combined_table = pa.concat_tables([row_group_0, row_group_1])\n",
    "pq.write_table(row_group_0, 'data/row_group_0.parquet')\n",
    "pq.write_table(combined_table, 'data/two_row_groups.parquet')\n"
   ],
   "id": "694ca40fd29aa7be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(parquet_file.metadata.num_row_groups):\n",
    "    row_group_stats = parquet_file.metadata.row_group(i).column(0).statistics\n",
    "    print(f\"row group: {i}, num of rows: {row_group_stats.num_values}\")"
   ],
   "id": "c9401360654f6847",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create subsample of train dataset to experiment with it",
   "id": "ddeb4964df399e12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# https://www.kaggle.com/code/andrewdblevins/leash-tutorial-ecfps-and-random-forest\n",
    "con = duckdb.connect()\n",
    "\n",
    "df = con.query(f\"\"\"(SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 0\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 3000000)\n",
    "                        UNION ALL\n",
    "                        (SELECT *\n",
    "                        FROM parquet_scan('{train_path}')\n",
    "                        WHERE binds = 1\n",
    "                        ORDER BY random()\n",
    "                        LIMIT 1589906)\"\"\").arrow()\n",
    "pq.write_table(df, 'data/subsampled_5M_train.parquet')\n",
    "\n",
    "con.close()"
   ],
   "id": "49da54737df577a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "row_group_df = parquet_file.read_row_group(0).to_pandas()\n",
    "row_group_df.to_csv('data/row_group_0.csv')"
   ],
   "id": "7fe294cff745badd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "row_group_df.info()",
   "id": "b51ddb74fbd2a716",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get statistics of the target column",
   "id": "8b1ab6428b4537c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "negative_count = 0\n",
    "positive_count = 0\n",
    "for i in range(parquet_file.metadata.num_row_groups):\n",
    "    row_group_df = parquet_file.read_row_group(i).to_pandas()\n",
    "    negative_count += row_group_df[TARGET_COLUMN].value_counts()[0]\n",
    "    positive_count += row_group_df[TARGET_COLUMN].value_counts()[1]\n",
    "    print(f\"row group: {i}, negative count: {negative_count}, positive count: {positive_count}\")"
   ],
   "id": "6f7f1352c4fa4f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_ = plt.bar(['log negative', 'log positive'], [np.log(negative_count), np.log(positive_count)])\n",
    "_ = plt.title('Target column distribution')"
   ],
   "id": "3b687606940fa802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Draw couple of molecules",
   "id": "7bc7408abb66d82d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "row_group_df = parquet_file.read_row_group(0).to_pandas()",
   "id": "494d07885af4e919",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "row_group_df[WHOLE_MOLECULE_COLUMN].head()",
   "id": "bdeda73ccec6bf2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "smiles = []\n",
    "targets = []\n",
    "for i in tqdm(range(parquet_file.metadata.num_row_groups)):\n",
    "    row_group_df = parquet_file.read_row_group(i).to_pandas()\n",
    "    negative_sample = row_group_df[row_group_df[TARGET_COLUMN] == 0].sample(2)\n",
    "    positive_sample = row_group_df[row_group_df[TARGET_COLUMN] == 1].sample(2)\n",
    "    subsample = pd.concat([negative_sample, positive_sample])\n",
    "    smiles.extend(subsample[WHOLE_MOLECULE_COLUMN].values)\n",
    "    targets.extend(subsample[TARGET_COLUMN].values)"
   ],
   "id": "ac173a916bcbef1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_mols_to_draw = 100\n",
    "random_indices = np.random.choice(len(smiles), num_mols_to_draw, replace=False)\n",
    "grid_size = math.ceil(np.sqrt(num_mols_to_draw))\n",
    "fig, axs = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "for i in tqdm(range(num_mols_to_draw)):\n",
    "    smile = smiles[random_indices[i]]\n",
    "    target = targets[random_indices[i]]\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    ax = axs[i // grid_size, i % grid_size]\n",
    "    ax.imshow(Draw.MolToImage(mol))\n",
    "    ax.set_title(f'target: {target}')\n",
    "ax.axis('off')"
   ],
   "id": "f82f86b0f5e127b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# XGBoost baseline",
   "id": "2ba77e9f8f587d1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Train validation split')\n",
    "train_file_path = 'data/row_group_0.parquet'\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "train_val_pq = pq.ParquetFile(train_file_path)\n",
    "train_indices = rng.choice(train_val_pq.metadata.num_rows, int(0.8 * train_val_pq.metadata.num_rows), replace=False)\n",
    "val_indices = np.setdiff1d(np.arange(train_val_pq.metadata.num_rows), train_indices)\n",
    "\n",
    "print('Creating datasets')\n",
    "train_dataset = SmilesIterator(train_file_path, indicies=train_indices, radius=3, test_set=False)\n",
    "val_dataset = SmilesIterator(train_file_path, indicies=val_indices, radius=3, test_set=False)\n",
    "test_dataset = SmilesIterator('data/test.parquet', shuffle=False, radius=3, test_set=True)"
   ],
   "id": "bc9f7144dd9a4fbc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_Xy = xgboost.DMatrix(train_dataset)",
   "id": "9fa5ad8ca3a42fad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val_Xy = xgboost.DMatrix(val_dataset)",
   "id": "907ae582a1bb2e1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_Xy = xgboost.DMatrix(test_dataset)",
   "id": "1ce38bc690884eb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Load model')\n",
    "model_path = 'logs/2024-04-25_22-04-59/model.pkl'\n",
    "with open(model_path, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "    "
   ],
   "id": "391c2252c6cb10d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Predicting')\n",
    "get_submission_test_predictions(test_dataset, test_Xy, model, 'logs/2024-04-25_22-04-59')"
   ],
   "id": "b8f4012537924e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Creating model')\n",
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'objective': 'binary:logistic',\n",
    "    # 'nthread': 4,\n",
    "    'eval_metric': 'auc',\n",
    "    'verbosity': 2\n",
    "}\n",
    "\n",
    "\n",
    "num_rounds = 10  # equivalent to the number of estimators\n",
    "\n",
    "eval_list = [(train_Xy, 'train'), (val_Xy, 'eval')]  # evaluation set for monitoring"
   ],
   "id": "60e7a3986ab5af75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = xgb.train(params, train_Xy, num_rounds, evals=eval_list, verbose_eval=100000)",
   "id": "ec1adfec70127253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the model using pickle\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ],
   "id": "9b8b68fae1006ab2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "21bc519b4a1a17d7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:binding_prediction]",
   "language": "python",
   "name": "conda-env-binding_prediction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
